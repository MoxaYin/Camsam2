"""
SAV-test æ•°æ®é›†è¯„ä¼°è„šæœ¬ï¼ˆSAM2.1 + Memory Bank æ¸…ç†ï¼‰

åŸºäº SAM2.1 å¤§æ¨¡å‹ï¼Œæ— éœ€ CamSAM2 å‚æ•°

æ•°æ®ç»“æ„ç†è§£ï¼š
- Annotations_6fps/video_0001/000/0.png = å¯¹è±¡000åœ¨å¸§0çš„GT
- Annotations_6fps/video_0001/001/0.png = å¯¹è±¡001åœ¨å¸§0çš„GT
- æ¯ä¸ªå¯¹è±¡åœ¨å„è‡ªçš„æ–‡ä»¶å¤¹ä¸­åŒ…å«å®Œæ•´çš„å¸§åºåˆ—
- æ‰€æœ‰å¯¹è±¡ä½¿ç”¨åŒä¸€ä¸ªJPEGImages_24fpsä¸­çš„è§†é¢‘å¸§æ¥åˆ†å‰²

æ”¹è¿›ç­–ç•¥ï¼š
1. Memory Bank æ¸…ç†æœºåˆ¶ï¼ˆMemory Bank Clearingï¼‰
   - ç›‘æ§æ©ç é¢ç§¯å˜åŒ–
   - å½“æŸå¸§æ©ç é¢ç§¯çªç„¶ç¼©å° 70% ä»¥ä¸Šæ—¶ï¼Œå¼ºåˆ¶æ¸…ç©ºæ—§ memory
   - æ¸…ç†åç»§ç»­æ¨ç†ï¼Œç­‰å¾…ç›®æ ‡é‡æ–°å‡ºç°
   - é˜²æ­¢é•¿è§†é¢‘åæœŸå› ç›®æ ‡æ¶ˆå¤±å¯¼è‡´åç»­å…¨é»‘çš„é—®é¢˜
"""
import os
import argparse
import numpy as np
import torch
from PIL import Image
import cv2
import sys

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sam2.build_sam import build_sam2_video_predictor


# ========================= è¾…åŠ©å‡½æ•° =========================

def resize_frame(frame, target_size):
    """ç¼©æ”¾å¸§åˆ°ç›®æ ‡å°ºå¯¸"""
    h, w = frame.shape[:2]
    new_h, new_w = target_size
    if (h, w) != (new_h, new_w):
        frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    return frame


def resize_mask(mask, target_size):
    """ç¼©æ”¾æ©ç åˆ°ç›®æ ‡å°ºå¯¸"""
    # ç¡®ä¿ target_size çš„å€¼éƒ½æ˜¯æœ‰æ•ˆçš„æ•´æ•°
    target_h, target_w = target_size
    if target_h <= 0 or target_w <= 0:
        raise ValueError(f"Invalid target size: {target_size}")
    
    # å¤„ç†ç©ºæ©ç 
    if mask is None or mask.size == 0:
        return np.zeros((target_h, target_w), dtype=bool)
    
    # è½¬æ¢ä¸º uint8ï¼Œé¿å… OpenCV å¸ƒå°”ç±»å‹ä¸å…¼å®¹é—®é¢˜
    if mask.dtype == bool:
        mask = mask.astype(np.uint8) * 255
    elif mask.dtype != np.uint8:
        mask = (mask > 0).astype(np.uint8) * 255
    
    h, w = mask.shape[:2]
    
    # éªŒè¯è¾“å…¥æ©ç çš„å°ºå¯¸
    if h <= 0 or w <= 0:
        return np.zeros((target_h, target_w), dtype=bool)
    
    if (h, w) != (target_h, target_w):
        # OpenCV resize éœ€è¦ (width, height) æ ¼å¼
        try:
            resized = cv2.resize(mask, (target_w, target_h), interpolation=cv2.INTER_NEAREST)
            return resized > 127
        except cv2.error as e:
            print(f"Warning: cv2.resize failed with {h}x{w} -> {target_h}x{target_w}: {e}")
            return np.zeros((target_h, target_w), dtype=bool)
    
    return mask > 127


def get_mask_area(mask):
    """è®¡ç®—æ©ç çš„é¢ç§¯ï¼ˆå‰æ™¯åƒç´ æ•°ï¼‰"""
    return np.sum(mask > 0)


# ========================= ä¸»è¦æ¨ç†å‡½æ•° =========================

def get_device():
    """è·å–è®¾å¤‡"""
    if torch.cuda.is_available():
        device = torch.device("cuda")
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
    else:
        device = torch.device("cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    if device.type == "cuda":
        torch.autocast("cuda", dtype=torch.float32).__enter__()
        if torch.cuda.get_device_properties(0).major >= 8:
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
    elif device.type == "mps":
        print("\næ³¨æ„: MPS æ”¯æŒå¤„äºè¯•éªŒé˜¶æ®µï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™")

    return device


def get_all_objects_in_video(video_annotation_dir):
    """
    è·å–è§†é¢‘ä¸­çš„æ‰€æœ‰åˆ†å‰²å¯¹è±¡ ID
    
    å‚æ•°ï¼š
        video_annotation_dir: è§†é¢‘çš„æ ‡æ³¨ç›®å½•ï¼ˆå¦‚ Annotations_6fps/video_0001/ï¼‰
    
    è¿”å›ï¼š
        sorted list of object IDsï¼ˆä¾‹å¦‚ [0, 1, 2]ï¼‰
    """
    object_dirs = sorted([d for d in os.listdir(video_annotation_dir) 
                         if os.path.isdir(os.path.join(video_annotation_dir, d))],
                        key=lambda x: int(x) if x.isdigit() else 999)
    return [int(obj_dir) for obj_dir in object_dirs]


def load_object_frames(object_dir):
    """
    åŠ è½½å•ä¸ªåˆ†å‰²å¯¹è±¡çš„æ‰€æœ‰å¸§æ•°æ®
    
    å‚æ•°ï¼š
        object_dir: å¯¹è±¡ç›®å½•ï¼ˆå¦‚ Annotations_6fps/video_0001/000/ï¼‰
    
    è¿”å›ï¼š
        {frame_id: mask_array, ...}
        ä¾‹å¦‚ï¼š{0: mask_array, 1: mask_array, ...}
    """
    frames_data = {}
    
    frame_files = sorted([f for f in os.listdir(object_dir)
                         if f.endswith('.png')],
                        key=lambda x: int(os.path.splitext(x)[0]))
    
    for frame_file in frame_files:
        frame_id = int(os.path.splitext(frame_file)[0])
        frame_mask = np.array(Image.open(os.path.join(object_dir, frame_file)))
        frames_data[frame_id] = frame_mask
    
    return frames_data


def get_frame_files(video_images_dir):
    """
    è·å–è§†é¢‘å¸§æ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰é¡ºåºï¼‰
    """
    frame_files = sorted([f for f in os.listdir(video_images_dir)
                         if f.endswith(('.jpg', '.jpeg', '.JPG', '.JPEG'))],
                        key=lambda x: int(os.path.splitext(x)[0]))
    return frame_files


def eval_single_object(video_name, object_id, annotations_path, images_path, 
                       output_path, predictor, 
                       enable_memory_clear=True, memory_clear_threshold=0.3):
    """
    å¯¹è§†é¢‘ä¸­çš„å•ä¸ªåˆ†å‰²å¯¹è±¡è¿›è¡Œæ¨ç†å’Œè¯„ä¼°
    
    å‚æ•°ï¼š
        video_name: è§†é¢‘åç§°ï¼ˆå¦‚ 'video_0001'ï¼‰
        object_id: å¯¹è±¡ IDï¼ˆå¦‚ 0, 1, 2ï¼‰
        annotations_path: Annotations_6fps çš„è·¯å¾„
        images_path: JPEGImages_24fps çš„è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„
        predictor: SAM2 è§†é¢‘é¢„æµ‹å™¨
        enable_multiscale: å¯ç”¨å¤šå°ºåº¦æ¨ç†
        enable_memory_clear: å¯ç”¨ Memory Bank æ¸…ç†æœºåˆ¶
        memory_clear_threshold: Memory æ¸…ç†é˜ˆå€¼ (0.3 = 70% ç¼©å°)
    
    è¿”å›ï¼š
        metrics dict æˆ– Noneï¼ˆå¦‚æœå‡ºé”™ï¼‰
    """
    try:
        # è·¯å¾„
        object_annotation_dir = os.path.join(annotations_path, video_name, f"{object_id:03d}")
        video_images_dir = os.path.join(images_path, video_name)
        
        if not os.path.exists(object_annotation_dir):
            print(f"      âš ï¸  å¯¹è±¡ç›®å½•ä¸å­˜åœ¨: {object_annotation_dir}")
            return None
        
        if not os.path.exists(video_images_dir):
            print(f"      âš ï¸  è§†é¢‘ç›®å½•ä¸å­˜åœ¨: {video_images_dir}")
            return None
        
        # åŠ è½½è¯¥å¯¹è±¡çš„æ‰€æœ‰å¸§ GT
        object_frames = load_object_frames(object_annotation_dir)
        
        if not object_frames:
            print(f"      âš ï¸  å¯¹è±¡æ— æœ‰æ•ˆå¸§æ•°æ®")
            return None
        
        # è·å–è§†é¢‘ä¸­çš„æ‰€æœ‰å¸§
        frame_files = get_frame_files(video_images_dir)
        total_frames = len(frame_files)
        
        # è·å–ç¬¬ä¸€å¸§çš„ mask ä½œä¸ºæç¤º
        first_frame_ids = sorted(object_frames.keys())
        first_frame_id = first_frame_ids[0]
        first_frame_mask = object_frames[first_frame_id]
        
        # éªŒè¯ç¬¬ä¸€å¸§æ©ç çš„æœ‰æ•ˆæ€§
        if first_frame_mask is None or first_frame_mask.size == 0:
            print(f"      âš ï¸  ç¬¬ä¸€å¸§æ©ç æ— æ•ˆ")
            return None
        
        h_orig, w_orig = first_frame_mask.shape[:2]
        if h_orig <= 0 or w_orig <= 0:
            print(f"      âš ï¸  ç¬¬ä¸€å¸§æ©ç å°ºå¯¸æ— æ•ˆ: {h_orig}x{w_orig}")
            return None
        
        # å•å°ºåº¦æ¨ç†
        prediction_to_eval = _inference_single_scale(
            predictor, video_images_dir, first_frame_id, 
            first_frame_mask, total_frames,
            enable_memory_clear, memory_clear_threshold
        )
        
        # æ³¨ï¼šæŒ‡æ ‡è¯„ä¼°å·²ç§»é™¤ï¼Œå°†åœ¨å•ç‹¬çš„è„šæœ¬ä¸­è¿›è¡Œ
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        save_dir = os.path.join(output_path, video_name, f"{object_id:03d}")
        os.makedirs(save_dir, exist_ok=True)
        
        # ç¡®ä¿ prediction_to_eval æ˜¯æ­£ç¡®æ ¼å¼
        if prediction_to_eval.dtype != np.uint8:
            # å¦‚æœæ˜¯å¸ƒå°”å€¼æˆ–æµ®ç‚¹æ•°ï¼Œè½¬æ¢ä¸º uint8 (0 æˆ– 255)
            if prediction_to_eval.dtype == bool:
                prediction_to_eval = prediction_to_eval.astype(np.uint8) * 255
            elif prediction_to_eval.dtype in [np.float32, np.float64]:
                prediction_to_eval = (prediction_to_eval > 0.5).astype(np.uint8) * 255
            else:
                prediction_to_eval = prediction_to_eval.astype(np.uint8)
        
        for i, pred_mask in enumerate(prediction_to_eval):
            save_file = os.path.join(save_dir, f"{i:05d}.png")
            # pred_mask å·²ç»æ˜¯ uint8 (0-255)ï¼Œå¯ä»¥ç›´æ¥ä¿å­˜
            cv2.imwrite(save_file, pred_mask)
        
        print(f"      âœ… å¯¹è±¡ {object_id:03d}: æ¨ç†å®Œæˆ")
        print(f"         ğŸ“ ç»“æœä¿å­˜åˆ°: {save_dir}")
        
        return True
        
    except Exception as e:
        print(f"      âŒ å¯¹è±¡ {object_id:03d} å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        
        # ä¿å­˜é”™è¯¯æ—¥å¿—
        try:
            save_dir = os.path.join(output_path, video_name, f"{object_id:03d}")
            os.makedirs(save_dir, exist_ok=True)
            error_log = os.path.join(save_dir, "ERROR.log")
            with open(error_log, 'w') as f:
                f.write(f"Object {object_id} inference failed\n")
                f.write(f"Error: {str(e)}\n")
        except:
            pass
        
        return None


def _inference_single_scale(predictor, video_images_dir, first_frame_id, 
                            first_frame_mask, total_frames,
                            enable_memory_clear, memory_clear_threshold):
    """
    å•å°ºåº¦æ¨ç†ï¼ˆå¯é€‰ï¼šå¯ç”¨ Memory Bank æ¸…ç†æœºåˆ¶ï¼‰
    
    Memory Bank æ¸…ç†é€»è¾‘ï¼š
    - ç›‘æ§æ©ç é¢ç§¯å˜åŒ–
    - å½“æ©ç é¢ç§¯ç¼©å°è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œæ¸…ç†Memoryå¹¶ä»è¯¥å¸§é‡æ–°åˆå§‹åŒ–
    - æ¸…ç†åç»§ç»­æ¨ç†åç»­å¸§ï¼Œç­‰å¾…ç›®æ ‡é‡æ–°å‡ºç°
    
    é”™è¯¯æ¢å¤é€»è¾‘ï¼š
    - å¦‚æœåœ¨æ¸…ç†åå‡ºç° AssertionErrorï¼Œä½¿ç”¨æœ€è¿‘æœ‰æ•ˆçš„ mask é‡æ–°åˆå§‹åŒ–
    - ä»ä¸‹ä¸€å¸§ç»§ç»­æ¨ç†ï¼Œè€Œä¸æ˜¯åœæ­¢
    """
    # åˆå§‹åŒ–æ¨ç†çŠ¶æ€
    inference_state = predictor.init_state(video_path=video_images_dir)
    predictor.reset_state(inference_state)
    
    # æ·»åŠ  mask æç¤ºï¼ˆåœ¨ç¬¬ä¸€å¸§ï¼‰
    ann_obj_id = 1
    _, out_obj_ids, out_mask_logits = predictor.add_new_mask(
        inference_state=inference_state,
        frame_idx=first_frame_id,
        obj_id=ann_obj_id,
        mask=first_frame_mask
    )
    
    # æ¨ç†æ•´ä¸ªè§†é¢‘ï¼Œæ”¯æŒ Memory Bank æ¸…ç†å’Œé”™è¯¯æ¢å¤
    video_segments = {}
    prev_mask_area = None
    memory_cleared = False
    memory_clear_frame = None  # è®°å½• Memory Clear è§¦å‘çš„å¸§å·
    frames_since_clear = 0
    failed_frames = 0
    next_start_frame = None  # ç”¨äºé”™è¯¯æ¢å¤åä»æŒ‡å®šå¸§å¼€å§‹
    last_valid_mask_before_clear = None  # è®°å½•æ¸…ç†å‰æœ€åä¸€ä¸ªæœ‰æ•ˆçš„mask
    
    # å¤–å±‚å¾ªç¯ç”¨äºé”™è¯¯æ¢å¤é‡è¯•
    while True:
        try:
            # å¦‚æœæœ‰ next_start_frameï¼Œä»è¯¥å¸§å¼€å§‹ç»§ç»­æ¨ç†
            if next_start_frame is not None:
                print(f"        Recovery: continuing from frame {next_start_frame}...")
                for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(
                    inference_state, start_frame_idx=next_start_frame
                ):
                    # å®‰å…¨æ€§æ£€æŸ¥
                    if len(out_obj_ids) == 0:
                        failed_frames += 1
                        continue
                    
                    mask = (out_mask_logits[0] > 0.0).cpu().numpy()
                    
                    # ç¡®ä¿æ©ç æ˜¯ 2D æ•°ç»„
                    if mask.ndim != 2:
                        if mask.ndim == 1:
                            failed_frames += 1
                            continue
                        elif mask.ndim == 3:
                            mask = mask[0]
                        else:
                            failed_frames += 1
                            continue
                    
                    video_segments[out_frame_idx] = {out_obj_ids[0]: mask}
                    
                    # ========== Memory Bank æ¸…ç†åçš„æ¢å¤é€»è¾‘ ==========
                    # å¦‚æœç›®æ ‡åœ¨æ¸…ç†åé‡æ–°å‡ºç°ï¼Œä½¿ç”¨æ¸…ç†å‰çš„æœ‰æ•ˆmaské‡æ–°åˆå§‹åŒ–
                    if memory_cleared and last_valid_mask_before_clear is not None:
                        curr_mask_area = get_mask_area(mask)
                        
                        # ç›®æ ‡é‡æ–°å‡ºç°ï¼šé¢ç§¯ä»æ¶ˆå¤±çŠ¶æ€æ¢å¤åˆ°æœ‰æ„ä¹‰çš„å¤§å°
                        if curr_mask_area > 100:  # ç®€å•å¯å‘å¼ï¼šè¶…è¿‡100åƒç´ è®¤ä¸ºæ˜¯çœŸæ­£çš„é‡æ–°å‡ºç°
                            print(
                                f"        [Memory Reinit] Frame {out_frame_idx}: Target reappeared (area={curr_mask_area}), reinitializing with previous valid mask..."
                            )
                            # ç”¨æ¸…ç†å‰çš„æœ‰æ•ˆmaské‡æ–°åˆå§‹åŒ–çŠ¶æ€
                            predictor.reset_state(inference_state)
                            _, _, _ = predictor.add_new_mask(
                                inference_state=inference_state,
                                frame_idx=memory_clear_frame,  # ç”¨æ¸…ç†æ—¶çš„å¸§å·
                                obj_id=ann_obj_id,
                                mask=last_valid_mask_before_clear,  # ç”¨æ¸…ç†å‰çš„æœ‰æ•ˆmask
                            )
                            memory_cleared = False
                            memory_clear_frame = None
                            last_valid_mask_before_clear = None
                            print("        [Memory Reinit] Reinitialization completed, continuing inference...")
                            # ç»§ç»­ä»å½“å‰å¸§æ¨ç†
                            prev_mask_area = curr_mask_area
                            continue
                        else:
                            # è¿˜æ˜¯é»‘å›¾ï¼Œç»§ç»­ç­‰å¾…
                            frames_since_clear += 1
                            continue
                
                # æ­£å¸¸å®Œæˆï¼Œè·³å‡ºå¤–å±‚å¾ªç¯
                next_start_frame = None
                break
            else:
                # ç¬¬ä¸€æ¬¡æ¨ç†ï¼Œä»å¤´å¼€å§‹
                for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):
                    # å®‰å…¨æ€§æ£€æŸ¥
                    if len(out_obj_ids) == 0:
                        failed_frames += 1
                        continue
                    
                    mask = (out_mask_logits[0] > 0.0).cpu().numpy()
                    
                    # ç¡®ä¿æ©ç æ˜¯ 2D æ•°ç»„
                    if mask.ndim != 2:
                        if mask.ndim == 1:
                            failed_frames += 1
                            continue
                        elif mask.ndim == 3:
                            mask = mask[0]
                        else:
                            failed_frames += 1
                            continue
                    
                    video_segments[out_frame_idx] = {out_obj_ids[0]: mask}
                    
                    # ========== Memory Bank æ¸…ç†æœºåˆ¶ ==========
                    if enable_memory_clear:
                        curr_mask_area = get_mask_area(mask)
                        
                        if not memory_cleared and prev_mask_area is not None:
                            area_ratio = curr_mask_area / (prev_mask_area + 1e-8)
                            
                            # æ©ç é¢ç§¯ç¼©å°è¶…è¿‡é˜ˆå€¼ - è®°å½•æ¸…ç†å‰çš„æœ‰æ•ˆmaskå¹¶ç»§ç»­æ¨ç†
                            if area_ratio < memory_clear_threshold:
                                print(
                                    f"        [Memory Clear] Frame {out_frame_idx}: Area drop {area_ratio:.2%}, preparing for memory clear..."
                                )
                                
                                # è®°å½•æ¸…ç†å‰æœ€åçš„æœ‰æ•ˆmaskï¼ˆå‰ä¸€å¸§ï¼‰ï¼Œç”¨äºç›®æ ‡é‡æ–°å‡ºç°æ—¶çš„æ¢å¤
                                last_valid_frame_before_clear = max(video_segments.keys()) - 1 if len(video_segments) > 1 else out_frame_idx
                                if last_valid_frame_before_clear in video_segments:
                                    last_valid_mask_before_clear = next(iter(video_segments[last_valid_frame_before_clear].values()))
                                
                                # æ¸…ç©ºæ—§ memoryï¼Œä½†è¿™æ¬¡ä¸ç«‹å³é‡æ–°åˆå§‹åŒ–
                                predictor.reset_state(inference_state)
                                memory_cleared = True
                                memory_clear_frame = out_frame_idx
                                frames_since_clear = 0
                                print("        [Memory Clear] Memory cleared, waiting for target to reappear...")
                                # é‡è¦ï¼šç»§ç»­æ¨ç†ï¼Œä¸é‡æ–°åˆå§‹åŒ–ï¼Œè¿™æ ·å¯ä»¥ç»§ç»­è¿½è¸ªæ¶ˆå¤±çš„ç›®æ ‡
                                prev_mask_area = curr_mask_area
                                continue
                        
                        # æ¸…ç†åç­‰å¾…ç›®æ ‡é‡æ–°å‡ºç°
                        if memory_cleared:
                            frames_since_clear += 1
                            prev_mask_area = curr_mask_area
                        else:
                            prev_mask_area = curr_mask_area
                
                # æ­£å¸¸å®Œæˆï¼Œè·³å‡ºå¤–å±‚å¾ªç¯
                break
        
        except AssertionError as e:
            print(f"        âš ï¸  AssertionError during propagation: {str(e)[:100]}")
            
            # å°è¯•ä»æœ€åæœ‰æ•ˆçš„å¸§æ¢å¤
            if len(video_segments) > 0:
                last_valid_frame = max(video_segments.keys())
                last_valid_mask = next(iter(video_segments[last_valid_frame].values()))
                
                # å¦‚æœå·²ç»åˆ°è¾¾æˆ–è¶…è¿‡æœ€åä¸€å¸§ï¼Œåˆ™ç»“æŸ
                if last_valid_frame + 1 >= total_frames:
                    print(f"        âœ“ Already reached end of video, using available frames")
                    break
                
                try:
                    print(
                        f"        ğŸ”„ Recovery: reinit from frame {last_valid_frame}, continue from {last_valid_frame + 1}"
                    )
                    predictor.reset_state(inference_state)
                    _, _, _ = predictor.add_new_mask(
                        inference_state=inference_state,
                        frame_idx=last_valid_frame,
                        obj_id=ann_obj_id,
                        mask=last_valid_mask,
                    )
                    next_start_frame = last_valid_frame + 1
                    memory_cleared = True
                    frames_since_clear = 0
                    # ç»§ç»­ while å¾ªç¯é‡è¯•
                    continue
                except Exception as recovery_error:
                    print(f"        âŒ Recovery failed: {str(recovery_error)[:100]}, stopping inference")
                    break
            else:
                print(f"        âŒ No valid frames to recover from, stopping inference")
                break
        
        except Exception as e:
            print(f"        âš ï¸  Error during propagation: {str(e)[:100]}")
            
            # å°è¯•ä»æœ€åæœ‰æ•ˆçš„å¸§æ¢å¤
            if len(video_segments) > 0:
                last_valid_frame = max(video_segments.keys())
                last_valid_mask = next(iter(video_segments[last_valid_frame].values()))
                
                if last_valid_frame + 1 >= total_frames:
                    print(f"        âœ“ Already reached end of video, using available frames")
                    break
                
                try:
                    print(
                        f"        ğŸ”„ Recovery: reinit from frame {last_valid_frame}, continue from {last_valid_frame + 1}"
                    )
                    predictor.reset_state(inference_state)
                    _, _, _ = predictor.add_new_mask(
                        inference_state=inference_state,
                        frame_idx=last_valid_frame,
                        obj_id=ann_obj_id,
                        mask=last_valid_mask,
                    )
                    next_start_frame = last_valid_frame + 1
                    memory_cleared = True
                    frames_since_clear = 0
                    continue
                except Exception as recovery_error:
                    print(f"        âŒ Recovery failed: {str(recovery_error)[:100]}, stopping inference")
                    break
            else:
                print(f"        âŒ No valid frames to recover from, stopping inference")
                break
    
    # æ”¶é›†æ¨ç†ç»“æœ
    prediction_to_eval = []
    for frame_idx in range(total_frames):
        if frame_idx in video_segments:
            for out_obj_id, out_mask in video_segments[frame_idx].items():
                prediction_to_eval.append(out_mask)
                break
        else:
            prediction_to_eval.append(np.zeros_like(first_frame_mask))
    
    if failed_frames > 0:
        print(f"        Info: {failed_frames} frames skipped due to inference issues")
    
    return np.array(prediction_to_eval)


def eval_video_all_objects(video_name, annotations_path, images_path, 
                           output_path, predictor, 
                           enable_memory_clear=True,
                           memory_clear_threshold=0.3):
    """
    å¯¹è§†é¢‘ä¸­çš„æ‰€æœ‰åˆ†å‰²å¯¹è±¡è¿›è¡Œæ¨ç†å’Œè¯„ä¼°
    
    è¿”å›ï¼š
        {object_id: metrics_dict, ...}
    """
    print(f"\nğŸ¬ å¤„ç†è§†é¢‘: {video_name}")
    
    video_annotation_dir = os.path.join(annotations_path, video_name)
    
    if not os.path.exists(video_annotation_dir):
        print(f"   âŒ æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {video_annotation_dir}")
        return {}
    
    # è·å–è¯¥è§†é¢‘ä¸­çš„æ‰€æœ‰å¯¹è±¡ ID
    object_ids = get_all_objects_in_video(video_annotation_dir)
    
    if not object_ids:
        print(f"   âš ï¸  æœªæ‰¾åˆ°åˆ†å‰²å¯¹è±¡")
        return {}
    
    print(f"   ğŸ“Š æ‰¾åˆ° {len(object_ids)} ä¸ªåˆ†å‰²å¯¹è±¡: {object_ids}")
    
    video_results = {}
    
    for object_id in object_ids:
        metrics = eval_single_object(
            video_name=video_name,
            object_id=object_id,
            annotations_path=annotations_path,
            images_path=images_path,
            output_path=output_path,
            predictor=predictor,
            enable_memory_clear=enable_memory_clear,
            memory_clear_threshold=memory_clear_threshold
        )
        
        if metrics is not None:
            video_results[object_id] = metrics
    
    return video_results


def parse_args():
    """å‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser("SAV-test è¯„ä¼°ï¼ˆMemory Bank æ¸…ç†ï¼‰", add_help=True)
    parser.add_argument("--model_cfg", type=str, default="sam2_hiera_t.yaml",
                        help="æ¨¡å‹é…ç½®æ–‡ä»¶")
    parser.add_argument("--ckpt_path", type=str, default="checkpoints/sam2_hiera_tiny.pt",
                        help="SAM2 æ¨¡å‹æƒé‡")
    parser.add_argument("--camsam2_extra", type=str, required=False,
                        help="CamSAM2 æ¨¡å—æƒé‡")
    parser.add_argument("--output_mode", type=str, default="combined_mask",
                        choices=["original_sam2_mask", "combined_mask"],
                        help="è¾“å‡ºæ¨¡å¼")
    parser.add_argument("--annotations_path", type=str, required=True,
                        help="Annotations_6fps è·¯å¾„")
    parser.add_argument("--images_path", type=str, required=True,
                        help="JPEGImages_24fps è·¯å¾„")
    parser.add_argument("--output_path", type=str, required=True,
                        help="è¾“å‡ºè·¯å¾„")
    parser.add_argument("--enable_memory_clear", action="store_true", default=True,
                        help="å¯ç”¨ Memory Bank æ¸…ç†æœºåˆ¶")
    parser.add_argument("--disable_memory_clear", action="store_true",
                        help="ç¦ç”¨ Memory Bank æ¸…ç†æœºåˆ¶")
    parser.add_argument("--memory_clear_threshold", type=float, default=0.3,
                        help="Memory æ¸…ç†é˜ˆå€¼ï¼ˆé¢ç§¯ç¼©å°æ¯”ä¾‹ï¼Œé»˜è®¤ 0.3 = 70%ï¼‰")
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    device = get_device()
    
    # å¤„ç†æ”¹è¿›ç­–ç•¥å¼€å…³
    enable_memory_clear = args.enable_memory_clear and not args.disable_memory_clear
    memory_clear_threshold = args.memory_clear_threshold
    
    # æ˜¾ç¤ºé…ç½®
    print(f"\n{'='*80}")
    print(f"SAV-test è¯„ä¼°ï¼ˆSAM2.1 + Memory Bank æ¸…ç†æœºåˆ¶ï¼‰")
    print(f"{'='*80}")
    print(f"æ¨¡å‹é…ç½®: {args.model_cfg}")
    print(f"æ¨¡å‹æƒé‡: {args.ckpt_path}")
    print(f"è¾“å‡ºè·¯å¾„: {os.path.abspath(args.output_path)}")
    print(f"\næ”¹è¿›ç­–ç•¥:")
    print(f"  â€¢ Memory Bank æ¸…ç†: {'å¯ç”¨ (é˜ˆå€¼={:.1%})'.format(1-memory_clear_threshold) if enable_memory_clear else 'ç¦ç”¨'}")
    print(f"{'='*80}\n")
    
    # æ„å»º SAM2 è§†é¢‘é¢„æµ‹å™¨
    print("ğŸ“¦ åŠ è½½ SAM2 æ¨¡å‹...")
    predictor = build_sam2_video_predictor(
        args.model_cfg, args.ckpt_path, device=device
    )
    print("âœ… SAM2 æ¨¡å‹åŠ è½½å®Œæˆ\n")
    
    # è·å–æ‰€æœ‰è§†é¢‘
    videos = sorted([v for v in os.listdir(args.annotations_path) 
                    if os.path.isdir(os.path.join(args.annotations_path, v))])
    
    print(f"ğŸ“¹ æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
    
    # è¯„ä¼°æ¯ä¸ªè§†é¢‘çš„æ‰€æœ‰å¯¹è±¡
    all_results = {}
    for video_name in videos:
        video_results = eval_video_all_objects(
            video_name=video_name,
            annotations_path=args.annotations_path,
            images_path=args.images_path,
            output_path=args.output_path,
            predictor=predictor,
            enable_memory_clear=enable_memory_clear,
            memory_clear_threshold=memory_clear_threshold
        )
        all_results[video_name] = video_results
    
    # æ¨ç†å®Œæˆ
    print("\n" + "="*80)
    print("ğŸ“Š æ¨ç†å®Œæˆï¼")
    
    # åˆ—å‡ºè¾“å‡ºç›®å½•ç»“æ„
    print(f"\nğŸ“‚ è¾“å‡ºç›®å½•ç»“æ„:")
    print(f"   {os.path.abspath(args.output_path)}/")
    try:
        video_count = 0
        object_count = 0
        for root, dirs, files in os.walk(args.output_path):
            level = root.replace(args.output_path, '').count(os.sep)
            if level == 0:
                video_count = len([d for d in dirs if d.startswith('sav_')])
            if level == 1 and 'sav_' in os.path.basename(root):
                object_count += len(dirs)
        
        print(f"   ğŸ“¹ è§†é¢‘æ•°: {video_count}")
        print(f"   ğŸ“Š å¯¹è±¡æ€»æ•°: {object_count}")
        print(f"   ğŸ’¾ æ©ç æ–‡ä»¶å·²ä¿å­˜")
    except:
        pass
    
    print(f"\nâœ… æ‰€æœ‰æ¨ç†ç»“æœå·²ä¿å­˜åˆ°: {os.path.abspath(args.output_path)}")
    print("ğŸ’¡ æç¤º: è¯·ä½¿ç”¨å•ç‹¬çš„è„šæœ¬è®¡ç®—æ¨ç†æŒ‡æ ‡ï¼ˆIoU, BIoU, TIoU ç­‰ï¼‰")
    print("="*80)


if __name__ == "__main__":
    main()
